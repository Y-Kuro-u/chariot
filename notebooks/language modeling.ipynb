{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "\n",
    "Let's try the language modeling task by using chariot and Tensorflow.\n",
    "\n",
    "* Download the text8 dataset by chazutsu.\n",
    "* Preprocess text8 by chariot.\n",
    "* Make model by TensorFlow (use tf.keras).\n",
    "* Train & evaluate the model.\n",
    "\n",
    "This tutorial needs following libraries.\n",
    "\n",
    "* chazutsu\n",
    "* tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def set_path():\n",
    "    if \"../\" not in sys.path:\n",
    "        sys.path.append(\"../\")\n",
    "    root_dir = Path.cwd()\n",
    "    return root_dir\n",
    "\n",
    "ROOT_DIR = set_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Language Modeling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read resource from the existed resource(if you want to retry, set force=True).\n"
     ]
    }
   ],
   "source": [
    "import chazutsu\n",
    "from chariot.storage import Storage\n",
    "\n",
    "storage = Storage.setup_data_dir(ROOT_DIR)\n",
    "r = chazutsu.datasets.Text8().download(storage.data_path(\"raw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anarchism originated as a term of abuse first ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  anarchism originated as a term of abuse first ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.train_data().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100000\n",
       "Name: sentence, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = r.train_data()\n",
    "train_data[\"sentence\"] = train_data[\"sentence\"].apply(lambda x: x[:100000])\n",
    "train_data[\"sentence\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the review text by chariot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chariot.transformer as ct\n",
    "from chariot.preprocessor import Preprocessor\n",
    "\n",
    "\n",
    "lm_processor = Preprocessor(\n",
    "                    text_transformers=[ct.text.UnicodeNormalizer()],\n",
    "                    tokenizer=ct.Tokenizer(lang=None),\n",
    "                    vocabulary=ct.Vocabulary(min_df=2, max_df=5000))\n",
    "\n",
    "preprocessed = lm_processor.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1549\n"
     ]
    }
   ],
   "source": [
    "print(len(lm_processor.vocabulary.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model by TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import keras as K\n",
    "\n",
    "\n",
    "vocab_size = lm_processor.vocabulary.count\n",
    "embedding_size = 50\n",
    "hidden_size = 75\n",
    "\n",
    "def make_model():\n",
    "    model = K.Sequential()\n",
    "    model.add(K.layers.Embedding(input_dim=vocab_size, output_dim=embedding_size))\n",
    "    model.add(K.layers.LSTM(hidden_size))\n",
    "    model.add(K.layers.Dense(vocab_size, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ico\\documents\\works\\chariot\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.5220610836986452, acc=0.9424999924376607\n"
     ]
    }
   ],
   "source": [
    "from chariot.feeder import LanguageModelFeeder\n",
    "\n",
    "\n",
    "feeder = LanguageModelFeeder({\"sentence\": ct.formatter.ShiftGenerator()})\n",
    "steps_per_epoch, generator = feeder.make_generator(preprocessed, batch_size=25, sequence_length=10,\n",
    "                                                   sequencial=False)\n",
    "\n",
    "metrics = model.fit_generator(generator(), steps_per_epoch, epochs=100, verbose=0)\n",
    "print(\"loss={}, acc={}\".format(metrics.history[\"loss\"][-1], metrics.history[\"acc\"][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try generating the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, lm_processor, model, sequence_length=10, iteration=20):\n",
    "    preprocessed = lm_processor.transform([seed_text])[0]\n",
    "\n",
    "    def pad_sequence(tokens, length):\n",
    "        if len(tokens) < length:\n",
    "            pad_size = length - len(tokens)\n",
    "            return tokens + [lm_processor.vocabulary.pad] * pad_size\n",
    "        elif len(tokens) > length:\n",
    "            return tokens[-length:]\n",
    "        else:\n",
    "            return tokens\n",
    "\n",
    "    for _ in range(iteration):\n",
    "        x = pad_sequence(preprocessed, sequence_length)\n",
    "        y = model.predict([x])[0]\n",
    "        w = np.random.choice(np.arange(len(y)), 1, p=y)[0]\n",
    "        preprocessed.append(w)\n",
    "    \n",
    "    decoded = lm_processor.inverse_transform([preprocessed])\n",
    "    text = \" \".join(decoded[0])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when you play patients anti up mainland student something interests european communism others on continues develop society individualist due distinct arab personal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"when you\", lm_processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i wish to called state established active impact also determining personal tend cnt many there from for programming asperger the a common toxin'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"i wish to\", lm_processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
